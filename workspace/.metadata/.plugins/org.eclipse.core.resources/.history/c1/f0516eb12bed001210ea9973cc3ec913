import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.FileStatus;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;

import types.Node;

/**
 * Hadoop program to run the k-means algorithm
 * @author stevenb
 * @date 15-07-2013
 */
public class KMeans extends Configured implements Tool {
	
	public static enum MapCounters { // Counters used for the Map tasks
		NODES, DANGLING_NODES, STRUCTURES,
		MASS_WRITTEN, TOTAL_WRITES
	}
	
	public static enum ReduceCounters { // Counters used for the Reduce tasks
		NODES, DANGLING_NODES, STRUCTURES,
		MASS_READ, TOTAL_READS
	}
	
	public static class Map extends Mapper<LongWritable, Text, LongWritable, Node> {
		
		@Override
		public void setup(Context context) {
			// TODO
		}
		
		@Override
		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
			// TODO
		}
		
		@Override
		public void cleanup(Context context) throws IOException, InterruptedException {
			// TODO
		}
	}
	
	public static class Partition extends Partitioner<LongWritable, Node> {
		@Override
		public int getPartition(LongWritable nodeId, Node node, int numPartitions) {
			if (numPartitions == 0) {
				return 0;
			}
			return (int) (nodeId.get() % numPartitions);
		}
	}
	
	public static class Reduce extends Reducer<LongWritable, Node, LongWritable, Text> {
		
		@Override
		public void setup(Context context) {
			// TODO
		}
		
		@Override
		public void reduce(LongWritable key, Iterable<Node> values, Context context) throws IOException, InterruptedException {
			// TODO
		}
		
		@Override
		public void cleanup(Context context) throws IOException {
			// TODO
		}
	}
	
	public static class MassDistributionMap extends Mapper<LongWritable, Text, LongWritable, Text> {
		
		@Override
		public void setup(Context context) {
			// TODO
		}
		
		@Override
		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
			// TODO
		}
	}
	
	/**
	 * Runs the second step of the Pagerank Algorithm
	 * Will distribute the lost Pagerank juice over all
	 *  the nodes and will adjust the Pagerank according
	 *  to the jump and link factor
	 * @param conf: the Configuration object for the Map/Reduce job
	 * @param basePath: String pointing to the base of the output files
	 * @param iteration: Integer containing the number of iterations the program will run
	 * 	used to adjust the Job and Path names accordingly
	 * @throws IOException for File adjustment and the starting of the job
	 * @throws InterruptedException for starting the job
	 * @throws ClassNotFoundException for starting the job
	 */
	public void phase2(Configuration conf, String basePath, int iteration) throws IOException, InterruptedException, ClassNotFoundException {
		String in = basePath + "/iter" + (iteration + 1) + "out";
		String out = basePath + "/iter" + (iteration + 1);
		
		Job phase2 = new Job(conf, "KMeans - Iteration " + (iteration + 1) + " - Phase 2"); // Main settings
		phase2.setJarByClass(Pagerank.class);
		FileInputFormat.setInputPaths(phase2, new Path(in)); // Input settings
		phase2.setInputFormatClass(TextInputFormat.class);
		FileOutputFormat.setOutputPath(phase2, new Path(out)); // Output settings
		phase2.setOutputFormatClass(TextOutputFormat.class);
		phase2.setOutputKeyClass(LongWritable.class);
		phase2.setOutputValueClass(Node.class);
		phase2.setMapperClass(MassDistributionMap.class); // Class settings
		phase2.setNumReduceTasks(0); // Set to zero, since no reduce tasks should be started
		
		long startTime = System.currentTimeMillis();
		if (phase2.waitForCompletion(true)) {
			System.out.println("Phase 2, Iteration " + (iteration + 1) + " Finished in " + (System.currentTimeMillis() - startTime) / 1000.0 + " seconds");
		}
	}
	
	/**
	 * Runs the first step of the Pagerank Algorithm
	 * Map: Will read in all the nodes of the graph and 
	 *  partitions those nodes their Pagerank, afterwards
	 *  it will send these partitions to their neighbors
	 * Reduce: Counts all the messages received per node
	 *  and increments its Pagerank accordingly
	 * @param conf: the Configuration object for the Map/Reduce job
	 * @param startPath: String holding the initial input path
	 * @param basePath: String pointing to the base of the output files
	 * @param iteration: Integer containing the number of iterations the program will run
	 * 	used to adjust the Job and Path names accordingly
	 * @return the total mass found in the Reduce found
	 * @throws IOException for File adjustment and the starting of the job
	 * @throws InterruptedException for starting the job
	 * @throws ClassNotFoundException for starting the job
	 */
	public void phase1(Configuration conf, String startPath, String basePath, int iteration) throws IOException, InterruptedException, ClassNotFoundException {
		String in = "";
		if (iteration == 0) { // If first iteration, use start path given
			in = startPath;
		}
		else { // else, use previous basePath
			in = basePath + "/iter" + iteration;
		}
		String out = basePath + "/iter" + (iteration + 1) + "out";
		int numPartitions = 0; // Count the number of file partitions, so the number of reduce tasks can equal the number of map tasks
		for (FileStatus s : FileSystem.get(conf).listStatus(new Path(startPath))) {
			if (s.getPath().getName().contains("part-")) {
				numPartitions++;
			}
		}
		
		Job phase1 = new Job(conf, "KMeans - Iteration " + (iteration + 1) + " - Phase 1"); // Main settings
		phase1.setJarByClass(Pagerank.class);
		FileInputFormat.setInputPaths(phase1, new Path(in)); // Input settings
		phase1.setInputFormatClass(TextInputFormat.class);
		FileOutputFormat.setOutputPath(phase1, new Path(out)); // Output settings
		phase1.setOutputFormatClass(TextOutputFormat.class);
		phase1.setOutputKeyClass(LongWritable.class);
		phase1.setOutputValueClass(Node.class);
		phase1.setMapperClass(Map.class); // Class settings
		phase1.setReducerClass(Reduce.class);
		phase1.setPartitionerClass(Partition.class);
		phase1.setNumReduceTasks(numPartitions);
		
		long startTime = System.currentTimeMillis();
		if (phase1.waitForCompletion(true)) {
			System.out.println("Phase 1, Iteration " + (iteration + 1) + " Finished in " + (System.currentTimeMillis() - startTime) / 1000.0 + " seconds");
		}
	}
	
	/**
	 * Will iterate over the two phases in order for the
	 *  specified number of iterations
	 * @param conf: Configuration object used for every Map/Reduce task initiated
	 * @param startPath: the initial input path as a String
	 * @param basePath: the base path as a String to put all the output and subsequently input files in
	 * @param iterations: the number of iterations to run the algorithm as an Integer
	 * @throws Exception from the phase1() and phase2() methods for starting 
	 * 		MapReduce jobs and opening/closing files
	 */
	private void iterate(Configuration conf, String startPath, String basePath, int iterations) throws Exception {
		System.out.printf("Startpath: %s Basepath: %s Iterations: %d\n", startPath, basePath, iterations);
		for (int i = 0; i < iterations; i++) {
			System.out.printf("Phase 1, Iteration %d will start\n\n;", i + 1);
			phase1(conf, startPath, basePath, i);
			System.out.printf("\n\nPhase 1, Iteration %d complete\nWill start phase 2, Iteration %d\n\n", i + 1, i + 1);
			phase2(conf, basePath, i);
			System.out.printf("\n\nPhase 2, Iteration %d complete\n", i + 1);
		}
	}
	
	/**
	 * Prints out the usages of this program in case the user
	 *  gave incorrect input
	 * @param numArgs: number of arguments in the String array object
	 */
	private int printUsage() {
		System.out.println("usage:\t <input path> <output path> <k mean points> <number of iterations>");
		ToolRunner.printGenericCommandUsage(System.out);
		return -1;
	}
	
	/**
	 * Runs the main program
	 * 
	 * @param args: String array of arguments given at start 
	 * @return -1 in case of error | 0 in case of success
	 * @throws Exception from the iterate() method
	 */
	@Override
	public int run(String[] args) throws Exception {
		int iterations = 0, kmeans = 0;
		String startPath = "", basePath = "";
		Configuration conf = new Configuration(getConf());
		
		// Set arguments
		if (args.length < 4) {
			System.err.println("Error: too few parameters given");
			return printUsage();
		}
		startPath = args[0];
		basePath = args[1];
		try {
			kmeans = Integer.parseInt(args[2]);
			iterations = Integer.parseInt(args[3]);
		} catch (NumberFormatException e) {
			System.err.println("Error: expected Integers instead of " + args[2] + " (arg 2) and " + args[3] + " (arg 3)");
			return printUsage();
		}
		
		// Create and start iterations
		iterate(conf, startPath, basePath, iterations);
		return 0;
	}
	
	public static void main(String[] args) throws Exception {
		int result = ToolRunner.run(new Configuration(), new Pagerank(), args);
		System.exit(result);
	}
}
